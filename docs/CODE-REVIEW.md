# Code-Review: jarvis-schlappa/pv-forecast

Reviewer: Claude | Datum: 06.02.2026 | Version: v0.1.0

Scope: VollstÃ¤ndige Source-Code-Analyse aller Module, Tests & Docs

## Executive Summary

Gesamtnote: 7.5/10 â€“ Ein bemerkenswert reifes Erstrelease mit professioneller Projektstruktur, exzellenter UX und solider Code-QualitÃ¤t. Das ML-Modell hat klare Verbesserungspotentiale, aber die Software-Engineering-Grundlage ist Ã¼berdurchschnittlich stark.

## ğŸ“Š Bewertungsmatrix

| Kategorie | Note | Gewicht | Kommentar |
|-----------|------|---------|-----------|
| Projektstruktur & Packaging | 9/10 | 15% | Vorbildlich |
| Code-QualitÃ¤t | 8/10 | 20% | Sauber, konsistent, gut dokumentiert |
| ML-Modell & Features | 5.5/10 | 25% | Solide Basis, aber groÃŸer Verbesserungsbedarf |
| Tests | 8/10 | 15% | 158 Tests, gute Coverage, E2E vorhanden |
| UX & Dokumentation | 9/10 | 15% | Herausragend fÃ¼r ein v0.1 |
| Architektur & Erweiterbarkeit | 7/10 | 10% | Saubere Module, aber noch nicht plugin-fÃ¤hig |

## ğŸŸ¢ StÃ¤rken (was wirklich gut ist)

### 1. Projektstruktur (9/10)

Das Projekt folgt durchgehend Python Best Practices:

- src/-Layout mit pyproject.toml + Hatchling Build-Backend â€“ modern und korrekt
- Optional Dependencies sauber getrennt: [xgb], [tune], [dev], [all]
- Ruff-Konfiguration mit sinnvollem Rule-Set (E, W, F, I, B, UP)
- CI/CD via GitHub Actions fÃ¼r Python 3.9â€“3.12
- XDG-konforme Pfade: ~/.config/pvforecast/ und ~/.local/share/pvforecast/

4.163 Zeilen Produktivcode, 3.649 Zeilen Tests â€“ ein Test:Code-Ratio von 0.88 ist fÃ¼r ein Solo-Projekt exzellent.

### 2. Code-QualitÃ¤t (8/10)

- Type Hints konsequent verwendet, inkl. from __future__ import annotations
- Google-Style Docstrings in allen Public Functions mit Args/Returns/Raises
- Dataclasses statt dictionaries fÃ¼r strukturierte Daten (Config, HourlyForecast, Forecast, CheckResult)
- Context Manager fÃ¼r DB-Verbindungen (db.connect())
- Saubere Error-Hierarchie: ValidationError, DependencyError, DataImportError, WeatherAPIError, ModelNotFoundError
- Graceful Degradation bei optionalen Dependencies (XGBoost, Optuna) â€“ mit spezifischen Fehlermeldungen inkl. Installationsanleitung

Besonders positiv: Die XGBoost-Fehlerbehandlung (Zeile 33-52 in model.py) unterscheidet zwischen "nicht installiert", "libomp fehlt" und "unbekannter Fehler" â€“ mit passenden LÃ¶sungshinweisen pro Plattform. Das ist herausragend durchdacht.

### 3. UX & Dokumentation (9/10)

- Setup-Wizard mit PLZ-Geocoding â€“ ungewÃ¶hnlich poliert fÃ¼r ein CLI-Tool
- pvforecast doctor â€“ ein diagnostisches Health-Check-Tool, das 368 Zeilen umfasst
- Progress-Anzeigen und Timing bei allen langwierigen Operationen
- Metriken-ErklÃ¤rung als PDF fÃ¼r Nicht-Experten â€“ wirklich durchdacht
- Deutsche Dokumentation fÃ¼r die Zielgruppe (E3DC-Nutzer in DACH)

### 4. Tests (8/10)

- 158 Tests Ã¼ber 7 Test-Module
- E2E-Integration-Tests mit populated_db Fixture (150 Stunden synthetische Daten)
- Edge Cases abgedeckt: leere DB, fehlende Spalten, BOM-CSV, ungÃ¼ltige Daten, Zeitumstellung
- Monkeypatch fÃ¼r Dependency-Tests (XGBoost/Optuna an/aus)
- conftest.py mit wiederverwendbaren Fixtures â€“ sauber getrennt

### 5. Robuste Infrastruktur

- Retry-Logic mit Exponential Backoff + Jitter (Zeile 43-122 in weather.py)
- Wetter-LÃ¼cken-Erkennung und automatisches Nachladen
- Abregelungs-Erkennung in E3DC-Daten (curtailed flag)
- Schema-Migration von v1 â†’ v2 (erweiterte Wetter-Features)
- Zeitumstellungs-Handling bei CSV-Import mit ambiguous="NaT"

## ğŸŸ¡ Verbesserungspotential

### 1. ML-Modell â€“ Feature Engineering (5/10)

Das Feature-Set (Zeile 126-169 in model.py) ist das schwÃ¤chste Glied des Projekts:

**Aktuelle Features (10 StÃ¼ck):**
```
hour, month, day_of_year, ghi, cloud_cover, temperature,
sun_elevation, wind_speed, humidity, dhi
```

**Was fehlt und den MAPE von 30% auf ~15-20% senken kÃ¶nnte:**

- **Zyklische Zeit-Features:** hour und month als lineare Integer fÃ¼hren dazu, dass das Modell nicht lernt, dass Stunde 23 und Stunde 0 benachbart sind. Stattdessen sin(2Ï€Â·hour/24) und cos(2Ï€Â·hour/24) verwenden â€“ ebenso fÃ¼r month und day_of_year.

- **Clear-Sky-Index (CSI):** Das VerhÃ¤ltnis ghi / ghi_clear_sky ist einer der mÃ¤chtigsten PrÃ¤diktoren fÃ¼r PV-Prognosen. Clear-Sky GHI lÃ¤sst sich leicht aus Sonnenstand und Extraterrestrial Radiation berechnen (oder direkt von Open-Meteo anfordern). Ein CSI von 0.8 sagt dem Modell "80% des theoretischen Maximums erreicht" â€“ viel informativer als absolute GHI.

- **DNI (Direct Normal Irradiance):** Open-Meteo bietet direct_normal_irradiance â€“ ein wichtiges Feature, das die Unterscheidung zwischen diffuser und direkter Strahlung ermÃ¶glicht.

- **Interaktions-Features:** ghi Ã— (1 - cloud_cover/100) als effektive Strahlung, temperature Ã— production (PV-Module verlieren ~0.4%/Â°C Ã¼ber 25Â°C)

- **Lag-Features:** FÃ¼r die today-Prognose: tatsÃ¤chlicher Ertrag der letzten 1-3 Stunden als Input. Das ist der stÃ¤rkste Kurzfrist-PrÃ¤diktor.

- **Anlagen-spezifische Features:** peak_kwp wird nirgends als Feature verwendet â€“ bei einer 10 kWp-Anlage ist 8000W realistisch, bei 3 kWp nicht.

### 2. SonnenhÃ¶hen-Berechnung (vereinfacht, aber ungenau)

Die eigene Implementierung (Zeile 84-123) ist eine starke Vereinfachung:

```python
solar_time = hour + lon / 15  # Grobe AnnÃ¤herung
```

Das ignoriert die Equation of Time (bis zu Â±16 Minuten Abweichung je nach Jahreszeit) und nutzt 3.14159 statt math.pi. FÃ¼r ein ML-Feature ist das vermutlich ausreichend, da das Modell die Abweichung lernen kann â€“ aber pvlib.solarposition wÃ¤re genauer und ein bereits vorhandener Standard. Die Dependency pvlib ist leichtgewichtig und wÃ¼rde gleichzeitig Clear-Sky-Modelle ermÃ¶glichen.

### 3. MAPE-Berechnung und Evaluation

**Gut:** MAPE wird nur fÃ¼r Stunden >100W berechnet (Zeile 333-338) â€“ das vermeidet die bekannte MAPE-Verzerrung bei kleinen Werten.

**Problem:** Es fehlen wichtige Metriken:

- **RMSE** â€“ zeigt, wie groÃŸ die AusreiÃŸer sind
- **RÂ²** â€“ wie viel Varianz wird erklÃ¤rt?
- **Skill Score vs. Persistence-Modell** â€“ DER Benchmark: "Ist das ML-Modell besser als â€šmorgen wie heute'?" Ohne diesen Vergleich ist unklar, ob das Modell Ã¼berhaupt Mehrwert liefert.
- **AufschlÃ¼sselung nach klar/bewÃ¶lkt** â€“ das Modell kÃ¶nnte bei Sonnenschein exzellent sein und bei Wolken versagen

### 4. Performance-Anti-Patterns

Drei Stellen im Code verwenden iterrows() oder apply() statt vektorisierter Operationen:

```python
# model.py:165 â€“ SonnenhÃ¶he pro Zeile berechnet
features["sun_elevation"] = df["timestamp"].apply(
    lambda ts: calculate_sun_elevation(int(ts), lat, lon)
)

# data_loader.py:156 â€“ Zeilenweise DB-Insert
for _, row in df.iterrows():
    conn.execute(...)

# weather.py:291 â€“ Zeilenweise Record-Erstellung
for _, row in df.iterrows():
    records.append(...)
```

Bei 62k DatensÃ¤tzen ist das noch vertretbar, aber numpy-vektorisierte Operationen fÃ¼r die SonnenhÃ¶he und executemany statt Einzel-Inserts wÃ¼rden die Trainingszeit bei grÃ¶ÃŸeren Datenmengen deutlich reduzieren. Der Weather-Bulk-Insert (weather.py:296) nutzt bereits executemany â€“ gut! Aber der data_loader.py Import nicht.

### 5. SQL-Injection-Risiko (niedrig, aber vorhanden)

Drei Stellen nutzen f-Strings fÃ¼r SQL:

```python
query += f" AND p.timestamp >= strftime('%s', '{since_year}-01-01')"
```

since_year kommt aus CLI-Input und ist als int typisiert â€“ das Risiko ist gering, aber es wÃ¤re sauberer, parameterisierte Queries zu verwenden:

```python
query += " AND p.timestamp >= strftime('%s', ?)"
params.append(f"{since_year}-01-01")
```

### 6. Pickle fÃ¼r Modell-Serialisierung

pickle.dump/load funktioniert, hat aber bekannte Nachteile:

- **Sicherheitsrisiko:** Pickle kann beliebigen Code ausfÃ¼hren
- **VersionsfragilitÃ¤t:** Modelle kÃ¶nnen nach sklearn-Updates unlesbar werden
- **Keine Metadaten-Inspektion ohne Laden**

Alternative: joblib (sklearn-Standard) oder skops fÃ¼r sichere Serialisierung. FÃ¼r ein lokales CLI-Tool ist Pickle vertretbar, aber fÃ¼r eine spÃ¤tere HA-Integration problematisch.

## ğŸ”´ Fehlende Features fÃ¼r den Praxis-Einsatz

### 1. Keine Home-Assistant-Integration

FÃ¼r deinen Use Case (10 kWp + Batterie + HA) ist dies der grÃ¶ÃŸte Blocker. Kein REST-API-Modus, kein MQTT, kein HA-Sensor. Die offenen Issues #36-39 adressieren das.

### 2. Kein automatischer Cron-Betrieb

Kein systemd-Service, kein Cron-Setup, kein --daemon-Modus.

### 3. Keine Konfidenzintervalle

Das Modell liefert nur Punktprognosen ("morgen 15 kWh"), aber keine UnsicherheitsschÃ¤tzung ("morgen 12-18 kWh mit 80% Wahrscheinlichkeit"). XGBoost kann mit quantile Objective leicht Quantil-Regression liefern.

### 4. Kein Online-Learning

Modell muss manuell nachtrainiert werden. Kein Feedback-Loop "Prognose vs. RealitÃ¤t".

## ğŸ—ï¸ Architektur-Bewertung

### Positiv

- Klare Modul-Trennung (6 Module mit jeweils einem Verantwortungsbereich)
- DB als zentrale Datenschicht mit JOIN-basiertem Feature-Merge
- Config-System mit YAML + CLI-Override
- Saubere Datenfluss-Trennung: Import â†’ DB â†’ Train â†’ Model â†’ Predict

### VerbesserungswÃ¼rdig

- cli.py ist mit 1034 Zeilen zu groÃŸ â€“ Output-Formatierung, Command-Handler und Argumentparsing sollten getrennt werden
- Kein Plugin-System fÃ¼r alternative Wetter-Provider (nur Open-Meteo hardcoded)
- Kein abstrakes Datenimport-Interface â€“ nur E3DC CSV wird unterstÃ¼tzt

## Detaillierte Code-Metriken

| Modul | Zeilen | Verantwortung | Bewertung |
|-------|--------|---------------|-----------|
| cli.py | 1.034 | CLI + Formatting | Zu groÃŸ, aufteilen |
| model.py | 878 | ML Train/Predict/Tune | KernstÃ¼ck, Feature Engineering zu dÃ¼nn |
| doctor.py | 368 | Diagnostik | Exzellent, Ã¼berraschend durchdacht |
| weather.py | 447 | Open-Meteo Client | Robust, Retry+Gap-Filling |
| validation.py | 312 | Input-Validierung | Sauber, umfassend |
| data_loader.py | 194 | E3DC CSV Import | Kompakt, korrekt |
| config.py | 194 | YAML Config | Sauber, validiert |
| db.py | 143 | SQLite Layer | Minimal aber ausreichend |
| setup.py | ~300 | Setup Wizard | Poliert |
| geocoding.py | ~250 | PLZ â†’ Koordinaten | Clever gelÃ¶st |

## Empfehlung: Top-5 Verbesserungen nach Impact

| # | MaÃŸnahme | GeschÃ¤tzter Impact auf MAPE | Aufwand |
|---|----------|----------------------------|---------|
| 1 | Zyklische Zeit-Features (sin/cos) | -3-5% | ğŸŸ¢ 30 Min |
| 2 | Clear-Sky-Index als Feature | -5-8% | ğŸŸ¡ 2-3 Std |
| 3 | Lag-Features fÃ¼r Today-Prognose | -3-5% (nur today) | ğŸŸ¡ 2-3 Std |
| 4 | DNI + weitere Open-Meteo Params | -2-3% | ğŸŸ¢ 1 Std |
| 5 | LightGBM statt XGBoost | -1-2% + schneller | ğŸŸ¢ 30 Min |

Kumuliert kÃ¶nnten diese 5 MaÃŸnahmen den MAPE von ~30% auf ~15-20% senken â€“ und damit das Erfolgskriterium aus der SPEC.md (<20%) erreichen.

## Fazit

pv-forecast ist ein **auÃŸergewÃ¶hnlich gut strukturiertes und dokumentiertes Solo-Projekt**, das als Software-Engineering-Leistung beeindruckt. Die Projektorganisation (SPEC, Changelog, PROJECT-STATUS, Issues, CI) ist professioneller als bei vielen Team-Projekten.

Die ML-Performance hat klaren Verbesserungsbedarf, aber die Code-Architektur bietet eine solide Basis dafÃ¼r. Die fÃ¼nf genannten Feature-Engineering-MaÃŸnahmen wÃ¤ren mit vertretbarem Aufwand (1-2 Tage) umsetzbar und kÃ¶nnten die Genauigkeit signifikant verbessern.

FÃ¼r den Einsatz in deinem Setup (10 kWp, Batterie, HA) fehlt aktuell die HA-Integration und die Prognosegenauigkeit fÃ¼r automatisierte Steuerung. Als Forschungs- und Lernprojekt ist es aber eine hervorragende Ausgangsbasis.
